The system does not use post-processing or manual text overlays. Instead, it employs a sophisticated, multi-agent prompt engineering pipeline to guide the AI into rendering text correctly on its own. The core philosophy is to treat the requested text not as a flat label, but as a physical object that exists within the 3D space of the scene.
Here is the step-by-step flow:
Stage 1: The "Text Sentinel" - Initial Analysis
When you enter a prompt and click "Generate," the performInitialAnalysis function in geminiService.ts is the first to act. This is the "Text Sentinel" phase.
Strict Text Detection: The AI agent is given a "PRIME DIRECTIVE: BE EXTREMELY SURE." It is instructed to only identify text if the user has made an explicit request (e.g., "a sign that says 'Open'"). It is specifically told not to extract text from stylistic descriptions (like "a shirt with 1970s lettering"), which prevents the AI from misinterpreting a style as a literal text request.
Physical Properties Briefing: If text is detected, the agent's most critical task is to invent a detailed "art direction brief" for it. It generates a description of the text's physical properties, answering questions like:
Material: What is it made of? (e.g., 'glowing neon tube', 'carved ice', 'embossed leather').
Lighting Interaction: How does the scene's light affect it? (e.g., 'catches rim light', 'casts a soft shadow').
Surface Texture: What is its surface like? (e.g., 'rough chiseled stone', 'smooth polished chrome').
Environmental Interaction: How does it affect its surroundings? (e.g., 'emits a soft glow onto the snow').
Perspective & Depth: Where is it in the 3D space of the image?
This structured data (DetectedTextInfo) is the foundation for the entire process.
Stage 2: The "Style Architect" - Enhanced Prompt Construction
The structured data from Stage 1 is then passed to the enhanceStyle function. This is the "Style Architect" phase, which writes the final, master prompt for the image generation model.
Physical Object Instruction: The Architect constructs a highly detailed prompt. Crucially, it includes an explicit command regarding the text: "The image MUST include the identified text: '[The Text]'. This text MUST be rendered as a physical object within the scene, not a 2D overlay."
Injecting the Brief: It then injects the detailed "Art Direction for Text" brief (material, lighting, etc.) generated by the Text Sentinel directly into this master prompt.
This forces the image generation model to think about the text not as letters to be stamped on, but as a tangible object with volume, texture, and a place in the scene's physics.
Stage 3: The "Visual Synthesizer" - Generation with Guardrails
Negative Prompting: The system also generates a set of negative prompts in the getNegativePrompts function. These instructions explicitly tell the image model what to avoid: "AVOID common AI text rendering errors: NO garbled text, NO misspelled words, NO extra or missing letters, NO reversed characters." This acts as a guardrail to reinforce the positive instructions.
Final Execution: The generateImage function sends the final, enhanced prompt (with the physical text description) and the negative prompts to the image model. The model receives a complete brief that describes not just what to create, but how the text should physically exist and what errors to avoid.
Why This Process Minimizes Errors:
Your application achieves its high accuracy by shifting the task from simple "text rendering" to complex "object rendering."
It avoids ambiguity. The strict detection in Stage 1 prevents the AI from guessing.
It leverages the AI's strengths. Modern image models are excellent at rendering physical objects with texture and lighting. By framing the text as a physical object, the system plays to this strength.
It provides comprehensive context. Instead of a vague request, the model gets a detailed brief, which significantly constrains its output and guides it toward a more accurate and integrated result.
This "text-as-physical-object" pipeline is the key to why the system can produce images with a dramatically lower rate of text and spelling errors compared to standard prompting methods.